{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stonker69\\Documents\\GitHub\\BiksStonks\\Forcasting_Models\\env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from model import Iwata_simple\n",
    "from data import IWATA_Classification_Sampler\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from utils import StandardScaler\n",
    "import pandas as pd\n",
    "import psycopg2 as pg\n",
    "import tqdm\n",
    "\n",
    "import os\n",
    "import sktime\n",
    "from sktime.datasets import load_from_tsfile_to_dataframe\n",
    "from utils_iwata.preprocess import preprocess_iwata\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_iwata(data_list_path='data_list.csv', \n",
    "#                  out_ds_path='preprocessed_iwata_ds', \n",
    "#                  original_ds_path='Univariate_ts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirectional = True\n",
    "seq_len=13\n",
    "pred_len=1 # must be one fore Iwata_simple\n",
    "enc_in = 1\n",
    "hidden_size = 64\n",
    "c_out = 1\n",
    "s_n_layers = 2\n",
    "batch_size = 32 # = support size\n",
    "direcs = 2 if bidirectional else 1\n",
    "model = Iwata_simple(enc_in, hidden_size, c_out, s_n_layers)\n",
    "support_set = torch.rand(batch_size, seq_len, enc_in)\n",
    "query_set = torch.rand(1, seq_len, enc_in)\n",
    "output = model(support_set, query_set)\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iwata_simple(\n",
      "  (support_encoder): LSTM(1, 32, num_layers=2, bidirectional=True)\n",
      "  (query_encoder): LSTM(1, 64)\n",
      "  (attention): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "  )\n",
      "  (g): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 10 24\n"
     ]
    }
   ],
   "source": [
    "class_ds = IWATA_Classification_Sampler(root_path='preprocessed_iwata_ds', \n",
    "                                        seq_len=seq_len, pred_len=pred_len, num_samples=1000,\n",
    "                                        flag='TRAIN', seed=seed)\n",
    "data_loader = DataLoader(\n",
    "            class_ds,\n",
    "            batch_size=1, # only works with one as they are sampled already from Q_N, S_N\n",
    "            shuffle=False,\n",
    "            drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\titers: 100, epoch: 1 | loss: 0.8599555\n",
      "\tspeed: 0.0186s/iter; left time: 183.8604s\n",
      "\titers: 100, epoch: 1 | loss: 0.0964473\n",
      "\tspeed: 0.0182s/iter; left time: 180.2401s\n",
      "\titers: 100, epoch: 1 | loss: 2.0093324\n",
      "\tspeed: 0.0183s/iter; left time: 181.1427s\n",
      "\titers: 100, epoch: 1 | loss: 0.0099179\n",
      "\tspeed: 0.0181s/iter; left time: 179.5575s\n",
      "\titers: 100, epoch: 1 | loss: 0.0000070\n",
      "\tspeed: 0.0190s/iter; left time: 188.5607s\n",
      "\titers: 100, epoch: 1 | loss: 0.0208042\n",
      "\tspeed: 0.0179s/iter; left time: 177.4838s\n",
      "\titers: 100, epoch: 1 | loss: 0.0575268\n",
      "\tspeed: 0.0181s/iter; left time: 178.9595s\n",
      "\titers: 100, epoch: 1 | loss: 0.0154225\n",
      "\tspeed: 0.0182s/iter; left time: 179.9302s\n",
      "\titers: 100, epoch: 1 | loss: 0.0306734\n",
      "\tspeed: 0.0180s/iter; left time: 177.9566s\n",
      "\titers: 100, epoch: 1 | loss: 0.5926484\n",
      "\tspeed: 0.0180s/iter; left time: 178.2969s\n",
      "\titers: 100, epoch: 2 | loss: 0.0192931\n",
      "\tspeed: 0.0177s/iter; left time: 157.6714s\n",
      "\titers: 100, epoch: 2 | loss: 0.0002157\n",
      "\tspeed: 0.0187s/iter; left time: 166.1436s\n",
      "\titers: 100, epoch: 2 | loss: 0.0000317\n",
      "\tspeed: 0.0183s/iter; left time: 162.6382s\n",
      "\titers: 100, epoch: 2 | loss: 0.0061329\n",
      "\tspeed: 0.0269s/iter; left time: 239.5716s\n",
      "\titers: 100, epoch: 2 | loss: 0.0511621\n",
      "\tspeed: 0.0303s/iter; left time: 269.6080s\n",
      "\titers: 100, epoch: 2 | loss: 0.8595615\n",
      "\tspeed: 0.0213s/iter; left time: 189.9656s\n",
      "\titers: 100, epoch: 2 | loss: 0.0102139\n",
      "\tspeed: 0.0216s/iter; left time: 192.5246s\n",
      "\titers: 100, epoch: 2 | loss: 3.9144855\n",
      "\tspeed: 0.0207s/iter; left time: 184.4144s\n",
      "\titers: 100, epoch: 2 | loss: 0.0078978\n",
      "\tspeed: 0.0221s/iter; left time: 196.5513s\n",
      "\titers: 100, epoch: 2 | loss: 0.1017221\n",
      "\tspeed: 0.0228s/iter; left time: 203.0538s\n",
      "\titers: 100, epoch: 3 | loss: 0.0359106\n",
      "\tspeed: 0.0239s/iter; left time: 188.5647s\n",
      "\titers: 100, epoch: 3 | loss: 0.0337110\n",
      "\tspeed: 0.0244s/iter; left time: 193.0586s\n",
      "\titers: 100, epoch: 3 | loss: 0.0239138\n",
      "\tspeed: 0.0264s/iter; left time: 208.3277s\n",
      "\titers: 100, epoch: 3 | loss: 0.2067595\n",
      "\tspeed: 0.0240s/iter; left time: 189.2438s\n",
      "\titers: 100, epoch: 3 | loss: 0.0244178\n",
      "\tspeed: 0.0238s/iter; left time: 188.4079s\n",
      "\titers: 100, epoch: 3 | loss: 0.1775698\n",
      "\tspeed: 0.0205s/iter; left time: 162.2318s\n",
      "\titers: 100, epoch: 3 | loss: 0.0916469\n",
      "\tspeed: 0.0224s/iter; left time: 177.2531s\n",
      "\titers: 100, epoch: 3 | loss: 0.6286639\n",
      "\tspeed: 0.0227s/iter; left time: 179.0411s\n",
      "\titers: 100, epoch: 3 | loss: 0.0711576\n",
      "\tspeed: 0.0227s/iter; left time: 179.5097s\n",
      "\titers: 100, epoch: 3 | loss: 0.0093909\n",
      "\tspeed: 0.0223s/iter; left time: 176.4345s\n",
      "\titers: 100, epoch: 4 | loss: 0.0655755\n",
      "\tspeed: 0.0242s/iter; left time: 166.6604s\n",
      "\titers: 100, epoch: 4 | loss: 0.0107389\n",
      "\tspeed: 0.0246s/iter; left time: 169.9091s\n",
      "\titers: 100, epoch: 4 | loss: 0.0190001\n",
      "\tspeed: 0.0218s/iter; left time: 150.3892s\n",
      "\titers: 100, epoch: 4 | loss: 0.0125733\n",
      "\tspeed: 0.0222s/iter; left time: 153.2434s\n",
      "\titers: 100, epoch: 4 | loss: 0.0020663\n",
      "\tspeed: 0.0234s/iter; left time: 161.7343s\n",
      "\titers: 100, epoch: 4 | loss: 0.8526424\n",
      "\tspeed: 0.0226s/iter; left time: 156.2194s\n",
      "\titers: 100, epoch: 4 | loss: 0.0007631\n",
      "\tspeed: 0.0225s/iter; left time: 155.5814s\n",
      "\titers: 100, epoch: 4 | loss: 0.2226481\n",
      "\tspeed: 0.0220s/iter; left time: 152.0203s\n",
      "\titers: 100, epoch: 4 | loss: 0.0080386\n",
      "\tspeed: 0.0287s/iter; left time: 197.8813s\n",
      "\titers: 100, epoch: 4 | loss: 0.0014391\n",
      "\tspeed: 0.0232s/iter; left time: 160.2855s\n",
      "\titers: 100, epoch: 5 | loss: 0.0028158\n",
      "\tspeed: 0.0224s/iter; left time: 131.9827s\n",
      "\titers: 100, epoch: 5 | loss: 0.0167909\n",
      "\tspeed: 0.0262s/iter; left time: 154.8597s\n",
      "\titers: 100, epoch: 5 | loss: 0.0011111\n",
      "\tspeed: 0.0247s/iter; left time: 145.9253s\n",
      "\titers: 100, epoch: 5 | loss: 0.0037953\n",
      "\tspeed: 0.0238s/iter; left time: 140.4055s\n",
      "\titers: 100, epoch: 5 | loss: 0.0343324\n",
      "\tspeed: 0.0221s/iter; left time: 130.4261s\n",
      "\titers: 100, epoch: 5 | loss: 0.1476876\n",
      "\tspeed: 0.0253s/iter; left time: 149.1601s\n",
      "\titers: 100, epoch: 5 | loss: 0.4320172\n",
      "\tspeed: 0.0229s/iter; left time: 134.8891s\n",
      "\titers: 100, epoch: 5 | loss: 0.0337158\n",
      "\tspeed: 0.0230s/iter; left time: 135.6134s\n",
      "\titers: 100, epoch: 5 | loss: 0.1453336\n",
      "\tspeed: 0.0227s/iter; left time: 133.6542s\n",
      "\titers: 100, epoch: 5 | loss: 0.0509610\n",
      "\tspeed: 0.0234s/iter; left time: 138.1797s\n",
      "\titers: 100, epoch: 6 | loss: 0.0732753\n",
      "\tspeed: 0.0229s/iter; left time: 112.1963s\n",
      "\titers: 100, epoch: 6 | loss: 0.0021460\n",
      "\tspeed: 0.0312s/iter; left time: 152.6437s\n",
      "\titers: 100, epoch: 6 | loss: 0.0684965\n",
      "\tspeed: 0.0271s/iter; left time: 132.6784s\n",
      "\titers: 100, epoch: 6 | loss: 0.0518553\n",
      "\tspeed: 0.0271s/iter; left time: 132.9434s\n",
      "\titers: 100, epoch: 6 | loss: 0.0010021\n",
      "\tspeed: 0.0267s/iter; left time: 130.8660s\n",
      "\titers: 100, epoch: 6 | loss: 0.8885105\n",
      "\tspeed: 0.0282s/iter; left time: 138.2044s\n",
      "\titers: 100, epoch: 6 | loss: 0.0000983\n",
      "\tspeed: 0.0217s/iter; left time: 106.5704s\n",
      "\titers: 100, epoch: 6 | loss: 0.0044954\n",
      "\tspeed: 0.0225s/iter; left time: 110.1413s\n",
      "\titers: 100, epoch: 6 | loss: 0.0227171\n",
      "\tspeed: 0.0232s/iter; left time: 113.7216s\n",
      "\titers: 100, epoch: 6 | loss: 0.0283722\n",
      "\tspeed: 0.0222s/iter; left time: 108.8650s\n",
      "\titers: 100, epoch: 7 | loss: 0.0050907\n",
      "\tspeed: 0.0222s/iter; left time: 86.7582s\n",
      "\titers: 100, epoch: 7 | loss: 0.0609765\n",
      "\tspeed: 0.0236s/iter; left time: 91.9935s\n",
      "\titers: 100, epoch: 7 | loss: 0.0081686\n",
      "\tspeed: 0.0215s/iter; left time: 83.8430s\n",
      "\titers: 100, epoch: 7 | loss: 0.0027125\n",
      "\tspeed: 0.0234s/iter; left time: 91.4303s\n",
      "\titers: 100, epoch: 7 | loss: 0.0013900\n",
      "\tspeed: 0.0241s/iter; left time: 94.0675s\n",
      "\titers: 100, epoch: 7 | loss: 0.0112321\n",
      "\tspeed: 0.0230s/iter; left time: 89.7730s\n",
      "\titers: 100, epoch: 7 | loss: 0.0163616\n",
      "\tspeed: 0.0300s/iter; left time: 116.9276s\n",
      "\titers: 100, epoch: 7 | loss: 0.1284240\n",
      "\tspeed: 0.0268s/iter; left time: 104.7011s\n",
      "\titers: 100, epoch: 7 | loss: 0.0010716\n",
      "\tspeed: 0.0241s/iter; left time: 94.1764s\n",
      "\titers: 100, epoch: 7 | loss: 0.0006078\n",
      "\tspeed: 0.0253s/iter; left time: 98.6157s\n",
      "\titers: 100, epoch: 8 | loss: 0.8150790\n",
      "\tspeed: 0.0233s/iter; left time: 67.4770s\n",
      "\titers: 100, epoch: 8 | loss: 0.0222101\n",
      "\tspeed: 0.0235s/iter; left time: 68.1892s\n",
      "\titers: 100, epoch: 8 | loss: 0.0681342\n",
      "\tspeed: 0.0226s/iter; left time: 65.4402s\n",
      "\titers: 100, epoch: 8 | loss: 0.0041213\n",
      "\tspeed: 0.0223s/iter; left time: 64.7888s\n",
      "\titers: 100, epoch: 8 | loss: 0.0056911\n",
      "\tspeed: 0.0211s/iter; left time: 61.2642s\n",
      "\titers: 100, epoch: 8 | loss: 0.0384146\n",
      "\tspeed: 0.0216s/iter; left time: 62.6116s\n",
      "\titers: 100, epoch: 8 | loss: 0.0857931\n",
      "\tspeed: 0.0224s/iter; left time: 64.8332s\n",
      "\titers: 100, epoch: 8 | loss: 0.0000387\n",
      "\tspeed: 0.0215s/iter; left time: 62.2301s\n",
      "\titers: 100, epoch: 8 | loss: 0.0076010\n",
      "\tspeed: 0.0214s/iter; left time: 62.1840s\n",
      "\titers: 100, epoch: 8 | loss: 0.0006190\n",
      "\tspeed: 0.0220s/iter; left time: 63.6741s\n",
      "\titers: 100, epoch: 9 | loss: 0.0000007\n",
      "\tspeed: 0.0216s/iter; left time: 41.0246s\n",
      "\titers: 100, epoch: 9 | loss: 0.0028526\n",
      "\tspeed: 0.0216s/iter; left time: 40.9739s\n",
      "\titers: 100, epoch: 9 | loss: 0.8655077\n",
      "\tspeed: 0.0214s/iter; left time: 40.6286s\n",
      "\titers: 100, epoch: 9 | loss: 0.0012067\n",
      "\tspeed: 0.0215s/iter; left time: 40.8167s\n",
      "\titers: 100, epoch: 9 | loss: 3.7092872\n",
      "\tspeed: 0.0218s/iter; left time: 41.4224s\n",
      "\titers: 100, epoch: 9 | loss: 0.0006125\n",
      "\tspeed: 0.0252s/iter; left time: 47.9018s\n",
      "\titers: 100, epoch: 9 | loss: 0.1987042\n",
      "\tspeed: 0.0258s/iter; left time: 48.9672s\n",
      "\titers: 100, epoch: 9 | loss: 0.0011294\n",
      "\tspeed: 0.0266s/iter; left time: 50.5377s\n",
      "\titers: 100, epoch: 9 | loss: 0.0140504\n",
      "\tspeed: 0.0250s/iter; left time: 47.5917s\n",
      "\titers: 100, epoch: 9 | loss: 0.1409622\n",
      "\tspeed: 0.0236s/iter; left time: 44.8022s\n",
      "\titers: 100, epoch: 10 | loss: 0.0300968\n",
      "\tspeed: 0.0242s/iter; left time: 21.7442s\n",
      "\titers: 100, epoch: 10 | loss: 0.0205873\n",
      "\tspeed: 0.0223s/iter; left time: 20.0558s\n",
      "\titers: 100, epoch: 10 | loss: 0.0278151\n",
      "\tspeed: 0.0228s/iter; left time: 20.5282s\n",
      "\titers: 100, epoch: 10 | loss: 0.0336228\n",
      "\tspeed: 0.0251s/iter; left time: 22.6177s\n",
      "\titers: 100, epoch: 10 | loss: 0.0191883\n",
      "\tspeed: 0.0260s/iter; left time: 23.4332s\n",
      "\titers: 100, epoch: 10 | loss: 0.0005552\n",
      "\tspeed: 0.0242s/iter; left time: 21.7803s\n",
      "\titers: 100, epoch: 10 | loss: 0.0710338\n",
      "\tspeed: 0.0240s/iter; left time: 21.6215s\n",
      "\titers: 100, epoch: 10 | loss: 4.8632193\n",
      "\tspeed: 0.0230s/iter; left time: 20.7025s\n",
      "\titers: 100, epoch: 10 | loss: 0.0001524\n",
      "\tspeed: 0.0285s/iter; left time: 25.6762s\n",
      "\titers: 100, epoch: 10 | loss: 0.1233122\n",
      "\tspeed: 0.0235s/iter; left time: 21.1393s\n",
      "Epoch 10/10 \t Time: 24.37s \t Loss: 0.1210\n"
     ]
    }
   ],
   "source": [
    "train_steps = len(data_loader)\n",
    "time_now = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = []\n",
    "    epoch_time = time.time()\n",
    "    iter_count = 0\n",
    "    for s_seq_x, q_seq_x, q_seq_y in data_loader:\n",
    "        s_seq_x = s_seq_x.float().squeeze(0).to(device) # support set\n",
    "        q_seq_x = q_seq_x.float().squeeze(0).to(device) # query set \n",
    "        q_seq_y = q_seq_y.float() # query set label \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(s_seq_x, q_seq_x)\n",
    "        loss = mse(output, q_seq_y)\n",
    "        train_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iter_count += 1\n",
    "        if (iter_count) % 100 == 0: \n",
    "            print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(iter_count, epoch + 1, loss.item()))\n",
    "            speed = (time.time()-time_now)/iter_count\n",
    "            left_time = speed*((epochs - epoch)*train_steps - iter_count)\n",
    "            print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "            iter_count = 0\n",
    "            time_now = time.time()\n",
    "\n",
    "train_loss = np.average(train_loss)\n",
    "print('Epoch {}/{} \\t Time: {:.2f}s \\t Loss: {:.4f}'.format(epoch+1, epochs, time.time() - epoch_time, train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save torch model \n",
    "path = 'checkpoints'\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "model_specific_tag = f'seed{seed},enc_in{enc_in},hidden_size{hidden_size},c_out{c_out},s_n_layers{s_n_layers}'\n",
    "model_name = 'iwata_simple_benchmark_' + model_specific_tag + '.pt'\n",
    "# torch.save(model.state_dict(), os.path.join(path, model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load saved weights \n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(path, model_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = os.listdir('preprocessed_iwata_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_test_timeseries(data_list):\n",
    "    n = 0\n",
    "    for data in data_list:\n",
    "        X,_ = load_from_tsfile_to_dataframe(f'preprocessed_iwata_ds/{data}/{data}_TEST.ts')\n",
    "        n += len(X)\n",
    "    return n\n",
    "total_rows = count_test_timeseries(class_ds.target_tasks) # this can take a couple of secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 10 24\n"
     ]
    }
   ],
   "source": [
    "samples_per_series = 100-seq_len-pred_len+1 \n",
    "percent_to_use = .5\n",
    "terminate_at = int(samples_per_series*percent_to_use)\n",
    "\n",
    "percent_of_rows_to_use = .3\n",
    "\n",
    "total_series = terminate_at * int(total_rows*percent_of_rows_to_use)\n",
    "series_evaluated = 0\n",
    "\n",
    "class_ds = IWATA_Classification_Sampler(root_path='preprocessed_iwata_ds', \n",
    "                                        seq_len=seq_len, pred_len=pred_len, num_samples=total_series,\n",
    "                                        flag='TRAIN', seed=seed)\n",
    "\n",
    "data_loader = DataLoader(\n",
    "            class_ds,\n",
    "            batch_size=1, # only works with one as they are sampled already from Q_N, S_N\n",
    "            shuffle=False,\n",
    "            drop_last=True)\n",
    "d_iter = iter(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminate at 43 - sample so many timeseries per row\n",
      "Total number of rows: 23484 - 7045 rows will be used\n",
      "Total number of series: 302935\n"
     ]
    }
   ],
   "source": [
    "print(f'Terminate at {terminate_at} - sample so many timeseries per row')\n",
    "print(f'Total number of rows: {total_rows} - {int(total_rows*percent_of_rows_to_use)} rows will be used')\n",
    "print(f'Total number of series: {total_series}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on ArrowHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating timeseries for ArrowHead:   0%|          | 0/52 [00:22<?, ?rows/s]\n",
      "Evaluating timeseries for ArrowHead: 100%|██████████| 52/52 [00:14<00:00,  3.57rows/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "metrics = dict()\n",
    "\n",
    "for data in class_ds.target_tasks:\n",
    "    metrics[data] = []\n",
    "    print('Evaluating on {}'.format(data))\n",
    "    X,_ = load_from_tsfile_to_dataframe(f'preprocessed_iwata_ds/{data}/{data}_TEST.ts')\n",
    "    # sample subset of rows \n",
    "    n = len(X['dim_0'])\n",
    "    rows_to_use = int(n*percent_of_rows_to_use)\n",
    "    X = X.sample(rows_to_use)\n",
    "\n",
    "    loss = 0\n",
    "    samples_per_data = 0\n",
    "    pbar = tqdm.tqdm(n, desc=f'Evaluating timeseries for {data}', total=len(X), unit='rows')\n",
    "    for row in X['dim_0']:\n",
    "        row = row.to_numpy()\n",
    "        windows = np.lib.stride_tricks.sliding_window_view(row, window_shape=seq_len+pred_len)\n",
    "        windows = random.sample(list(windows), min(terminate_at, len(windows))) # sample \n",
    "        # sample once per row\n",
    "        s_seq_x, _, _ = next(d_iter) # advance the iterator\n",
    "        for i in range(0, min(terminate_at, len(windows))):\n",
    "            x, y = windows[i][:seq_len], windows[i][seq_len:]\n",
    "            series_evaluated += 1\n",
    "            # evaluate here \n",
    "            q_seq_x = torch.tensor(x[None,...,None]).float().to(device)\n",
    "            q_seq_y = torch.tensor(y).float().to(device)\n",
    "            s_seq_x = s_seq_x.float().squeeze(0).to(device)\n",
    "            output = model(s_seq_x, q_seq_x)\n",
    "            loss += mse(output, q_seq_y)\n",
    "            samples_per_data += 1\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "    metrics[data] = [loss/samples_per_data, torch.sqrt(loss/samples_per_data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(f'iwata_few_shot_benchmark_{model_specific_tag}.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['dataset name', 'MSE', 'RMSE']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for key, val in metrics.items():\n",
    "        writer.writerow({'dataset name': key, 'MSE': val[0].item(), 'RMSE': val[1].item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "559d4190745a361518ad4d4fb866dbc68a1fa7e52f9c7f667db13a1490771d76"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
