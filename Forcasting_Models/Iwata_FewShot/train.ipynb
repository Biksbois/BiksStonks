{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from model import Iwata_simple\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from utils import StandardScaler\n",
    "import pandas as pd\n",
    "import psycopg2 as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirectional = True\n",
    "seq_len=13\n",
    "enc_in = 5\n",
    "hidden_size = 64\n",
    "c_out = 1\n",
    "s_n_layers = 2\n",
    "batch_size = 32 # = support size\n",
    "direcs = 2 if bidirectional else 1\n",
    "model = Iwata_simple(enc_in, hidden_size, c_out, s_n_layers)\n",
    "support_set = torch.rand(batch_size, seq_len, enc_in)\n",
    "query_set = torch.rand(1, seq_len, enc_in)\n",
    "output = model(support_set, query_set)\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iwata_simple(\n",
      "  (support_encoder): LSTM(5, 32, num_layers=2, bidirectional=True)\n",
      "  (query_encoder): LSTM(5, 64)\n",
      "  (attention): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "  )\n",
      "  (g): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "S = torch.rand(batch_size, seq_len, enc_in)\n",
    "Q = torch.rand(1, seq_len, enc_in)\n",
    "y = torch.rand(c_out)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_f = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 \t Time: 0.02s \t Loss: 0.0000\n",
      "Epoch: 2/10 \t Time: 0.03s \t Loss: 0.2903\n",
      "Epoch: 3/10 \t Time: 0.02s \t Loss: 0.0175\n",
      "Epoch: 4/10 \t Time: 0.02s \t Loss: 0.0456\n",
      "Epoch: 5/10 \t Time: 0.02s \t Loss: 0.1187\n",
      "Epoch: 6/10 \t Time: 0.02s \t Loss: 0.0704\n",
      "Epoch: 7/10 \t Time: 0.02s \t Loss: 0.0190\n",
      "Epoch: 8/10 \t Time: 0.02s \t Loss: 0.0009\n",
      "Epoch: 9/10 \t Time: 0.02s \t Loss: 0.0075\n",
      "Epoch: 10/10 \t Time: 0.02s \t Loss: 0.0042\n",
      "Epoch 10/10 \t Time: 0.02s \t Loss: 0.0042\n"
     ]
    }
   ],
   "source": [
    "batch_s, batch_Q, y = S, Q, y\n",
    "# batch_s = batch_s.to(device)\n",
    "# batch_Q = batch_Q.to(device)\n",
    "# y = y.to(device)\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_loss = []\n",
    "    epoch_time = time.time()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    output = model(batch_s, batch_Q)\n",
    "    loss = loss_f(output, y)\n",
    "    train_loss.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch: {}/{} \\t Time: {:.2f}s \\t Loss: {:.4f}'.format(\n",
    "        epoch+1, epochs, time.time() - epoch_time, loss.item()))\n",
    "\n",
    "train_loss = np.average(train_loss)\n",
    "print('Epoch {}/{} \\t Time: {:.2f}s \\t Loss: {:.4f}'.format(epoch+1, epochs, time.time() - epoch_time, train_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iwata_Dataset_DB_Stock(torch.utils.data.Dataset):\n",
    "    def __init__(self, conn, S_N, Q_N, sup_stck_ids=None, q_stck_ids=None, flag='train', size=None, \n",
    "                 features='M', data_path='ETTh1.csv', \n",
    "                 target='close', scale=True, inverse=False,):\n",
    "        # size [seq_len, label_len, pred_len]\n",
    "        # info\n",
    "        assert len(size)==3\n",
    "        # init\n",
    "        assert flag in ['train', 'test']\n",
    "        type_map = {'train':0, 'test':1}\n",
    "        self.set_type = type_map[flag]\n",
    "        \n",
    "        self.agg = {'open': 'first',\n",
    "        'high': 'max', \n",
    "        'low': 'min', \n",
    "        'close': 'last',\n",
    "        'volume': 'sum'}\n",
    "        self.freq = '1T'\n",
    "        self.conn = conn\n",
    "        self.S_N = S_N\n",
    "        self.Q_N = Q_N\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.scale = scale\n",
    "        self.inverse = inverse\n",
    "        self.seq_len = size[0]\n",
    "        self.label_len = size[1]\n",
    "        self.pred_len = size[2] \n",
    "        assert self.pred_len == 1 # for now \n",
    "\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __stock_id_to_df__(self, stock_id, pg_conn, agg, sample_freq):\n",
    "        query = f'SELECT time AS date, open, high, low, volume, close \\\n",
    "                            FROM stock WHERE identifier = {stock_id} \\\n",
    "                            ORDER BY time ASC;'\n",
    "        df = pd.read_sql(query, pg_conn)\n",
    "        df.set_index(pd.DatetimeIndex(df['date']), inplace=True)\n",
    "        # resample \n",
    "        df = df.resample(sample_freq).agg(agg).dropna()\n",
    "        df.reset_index(inplace=True)\n",
    "        return df\n",
    "\n",
    "    def __read_data__(self):\n",
    "        \"\"\"Reads Q_N df from the db as the query set, and S_N df from the db as the support set.\n",
    "           - Only works for random selection of stocks currently.\"\"\"\n",
    "        \n",
    "        # sample stock ids \n",
    "        stock_meta = pd.read_sql('SELECT dataset.identifier AS id, dataset.description AS name \\\n",
    "                                 FROM dataset;', self.conn)\n",
    "        self.S_stock_meta = stock_meta.sample(n=self.S_N)\n",
    "        self.Q_stock_meta = stock_meta.sample(n=self.Q_N)\n",
    "        \n",
    "        # read data\n",
    "        '''\n",
    "        df.columns: ['date', ...(other features), target feature]\n",
    "        '''\n",
    "        S_dfs = []\n",
    "        Q_dfs = []\n",
    "        for s_id in self.S_stock_meta.id:\n",
    "            S_dfs.append(self.__stock_id_to_df__(s_id, self.conn, self.agg, self.freq))\n",
    "        \n",
    "        for q_id in self.Q_stock_meta.id:\n",
    "            Q_dfs.append(self.__stock_id_to_df__(q_id, self.conn, self.agg, self.freq))\n",
    "\n",
    "        # only tuned for Q_N = 1\n",
    "        cols = list(Q_dfs[0].columns); cols.remove(self.target); cols.remove('date')\n",
    "        df_raw = Q_dfs[0][['date']+cols+[self.target]]\n",
    "\n",
    "        num_train = int(len(df_raw)*0.7)\n",
    "        num_test = len(df_raw) - num_train\n",
    "        border1s = [0, num_train-self.seq_len]\n",
    "        border2s = [num_train, len(df_raw)]\n",
    "        border1 = border1s[self.set_type]\n",
    "        border2 = border2s[self.set_type]\n",
    "        \n",
    "        if self.features=='M' or self.features=='MS':\n",
    "            cols_data = df_raw.columns[1:]\n",
    "        elif self.features=='S':\n",
    "            cols_data = [self.target]\n",
    "\n",
    "        self.S_dfs_x = []\n",
    "        self.Q_dfs_x = []\n",
    "        if self.scale:\n",
    "            self.s_scalers = [StandardScaler() for i in range(self.S_N)]\n",
    "            self.q_scalers = [StandardScaler() for i in range(self.Q_N)]\n",
    "            for i in range(self.S_N):\n",
    "                train_data = S_dfs[i][cols_data][border1s[0]:border2s[0]]\n",
    "                self.s_scalers[i].fit(train_data)\n",
    "                self.S_dfs_x.append(self.s_scalers[i].transform(S_dfs[i][cols_data][border1:border2]))\n",
    "            for i in range(self.Q_N):\n",
    "                train_data = Q_dfs[i][cols_data][border1s[0]:border2s[0]]\n",
    "                self.q_scalers[i].fit(train_data)\n",
    "                self.Q_dfs_x.append(self.q_scalers[i].transform(Q_dfs[i][cols_data][border1:border2]))\n",
    "        else:\n",
    "            for i in range(self.S_N):\n",
    "                self.S_dfs_x.append(S_dfs[i][cols_data][border1:border2])\n",
    "            for i in range(self.Q_N):\n",
    "                self.Q_dfs_x.append(Q_dfs[i][cols_data][border1:border2])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end\n",
    "        r_end = r_begin + self.pred_len\n",
    "\n",
    "        # check date for all support set is < query index data\n",
    "        # query_date = self.Q_dfs[0].iloc[index]['date']\n",
    "        # for i in range(self.S_N):\n",
    "        #     s_date = self.S_dfs[i].iloc[0]['date']\n",
    "        #     # check support set date - \n",
    "\n",
    "        q_seq_x = self.Q_dfs_x[0][s_begin:s_end][:-1] # remove target\n",
    "        q_seq_y = seq_y = self.Q_dfs_x[0][r_begin:r_end][-1]\n",
    "\n",
    "        # randomly sample support sequence for each support timeseries \n",
    "        # (only works for Q_N = 1)\n",
    "        s_seq_x = []\n",
    "        for i in range(self.S_N):\n",
    "            end = len(self.S_dfs_x[i]) - self.label_len - self.pred_len\n",
    "            s_begin = np.random.randint(0, end)\n",
    "            s_end = s_begin + self.seq_len\n",
    "            r_begin = s_end\n",
    "            r_end = r_begin + self.pred_len\n",
    "            s_seq_x.append(self.S_dfs_x[i][s_begin:s_end][:-1])\n",
    "\n",
    "        s_seq_x = np.array(s_seq_x)\n",
    "            \n",
    "        return s_seq_x, q_seq_x, q_seq_y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_x) - self.seq_len- self.pred_len + 1\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler.inverse_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\msmic\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "conn = pg.connect(database='stonksdb', user='postgres', password='admin')\n",
    "iwata_stck_ds = Iwata_Dataset_DB_Stock(conn, 32, 1, size=[seq_len, seq_len, 1], flag='train', features='M', scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "-1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/msmic/Documents/code/schl/Informer2020/env/lib/site-packages/pandas/core/indexes/base.py?line=3619'>3620</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/msmic/Documents/code/schl/Informer2020/env/lib/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   <a href='file:///c%3A/Users/msmic/Documents/code/schl/Informer2020/env/lib/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: -1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\msmic\\Documents\\code\\schl\\BiksStonks\\Forcasting_Models\\Iwata_FewShot\\train.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/msmic/Documents/code/schl/BiksStonks/Forcasting_Models/Iwata_FewShot/train.ipynb#ch0000037?line=0'>1</a>\u001b[0m iwata_stck_ds\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(\u001b[39m0\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\msmic\\Documents\\code\\schl\\BiksStonks\\Forcasting_Models\\Iwata_FewShot\\train.ipynb Cell 7'\u001b[0m in \u001b[0;36mIwata_Dataset_DB_Stock.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/msmic/Documents/code/schl/BiksStonks/Forcasting_Models/Iwata_FewShot/train.ipynb#ch0000034?line=106'>107</a>\u001b[0m \u001b[39m# check date for all support set is < query index data\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/msmic/Documents/code/schl/BiksStonks/Forcasting_Models/Iwata_FewShot/train.ipynb#ch0000034?line=107'>108</a>\u001b[0m \u001b[39m# query_date = self.Q_dfs[0].iloc[index]['date']\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/msmic/Documents/code/schl/BiksStonks/Forcasting_Models/Iwata_FewShot/train.ipynb#ch0000034?line=108'>109</a>\u001b[0m \u001b[39m# for i in range(self.S_N):\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/msmic/Documents/code/schl/BiksStonks/Forcasting_Models/Iwata_FewShot/train.ipynb#ch0000034?line=109'>110</a>\u001b[0m \u001b[39m#     s_date = self.S_dfs[i].iloc[0]['date']\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/msmic/Documents/code/schl/BiksStonks/Forcasting_Models/Iwata_FewShot/train.ipynb#ch0000034?line=110'>111</a>\u001b[0m \u001b[39m#     # check support set date - \u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/msmic/Documents/code/schl/BiksStonks/Forcasting_Models/Iwata_FewShot/train.ipynb#ch0000034?line=112'>113</a>\u001b[0m q_seq_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mQ_dfs_x[\u001b[39m0\u001b[39m][s_begin:s_end][:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m# remove target\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/msmic/Documents/code/schl/BiksStonks/Forcasting_Models/Iwata_FewShot/train.ipynb#ch0000034?line=113'>114</a>\u001b[0m q_seq_y \u001b[39m=\u001b[39m seq_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mQ_dfs_x[\u001b[39m0\u001b[39;49m][r_begin:r_end][\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/msmic/Documents/code/schl/BiksStonks/Forcasting_Models/Iwata_FewShot/train.ipynb#ch0000034?line=115'>116</a>\u001b[0m \u001b[39m# randomly sample support sequence for each support timeseries \u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/msmic/Documents/code/schl/BiksStonks/Forcasting_Models/Iwata_FewShot/train.ipynb#ch0000034?line=116'>117</a>\u001b[0m \u001b[39m# (only works for Q_N = 1)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/msmic/Documents/code/schl/BiksStonks/Forcasting_Models/Iwata_FewShot/train.ipynb#ch0000034?line=117'>118</a>\u001b[0m s_seq_x \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32m~\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/msmic/Documents/code/schl/Informer2020/env/lib/site-packages/pandas/core/frame.py?line=3502'>3503</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/msmic/Documents/code/schl/Informer2020/env/lib/site-packages/pandas/core/frame.py?line=3503'>3504</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> <a href='file:///c%3A/Users/msmic/Documents/code/schl/Informer2020/env/lib/site-packages/pandas/core/frame.py?line=3504'>3505</a>\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   <a href='file:///c%3A/Users/msmic/Documents/code/schl/Informer2020/env/lib/site-packages/pandas/core/frame.py?line=3505'>3506</a>\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   <a href='file:///c%3A/Users/msmic/Documents/code/schl/Informer2020/env/lib/site-packages/pandas/core/frame.py?line=3506'>3507</a>\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\Documents\\code\\schl\\Informer2020\\env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/msmic/Documents/code/schl/Informer2020/env/lib/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   <a href='file:///c%3A/Users/msmic/Documents/code/schl/Informer2020/env/lib/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> <a href='file:///c%3A/Users/msmic/Documents/code/schl/Informer2020/env/lib/site-packages/pandas/core/indexes/base.py?line=3622'>3623</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/msmic/Documents/code/schl/Informer2020/env/lib/site-packages/pandas/core/indexes/base.py?line=3623'>3624</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/msmic/Documents/code/schl/Informer2020/env/lib/site-packages/pandas/core/indexes/base.py?line=3624'>3625</a>\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/msmic/Documents/code/schl/Informer2020/env/lib/site-packages/pandas/core/indexes/base.py?line=3625'>3626</a>\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/msmic/Documents/code/schl/Informer2020/env/lib/site-packages/pandas/core/indexes/base.py?line=3626'>3627</a>\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/msmic/Documents/code/schl/Informer2020/env/lib/site-packages/pandas/core/indexes/base.py?line=3627'>3628</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: -1"
     ]
    }
   ],
   "source": [
    "iwata_stck_ds.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3028, 5)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iwata_stck_ds.Q_dfs_x[0].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Iwata_Dataset_DB_Stock' object has no attribute 'S_dfs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\msmic\\Documents\\code\\schl\\BiksStonks\\Forcasting_Models\\Iwata_FewShot\\train.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/msmic/Documents/code/schl/BiksStonks/Forcasting_Models/Iwata_FewShot/train.ipynb#ch0000040?line=0'>1</a>\u001b[0m iwata_stck_ds\u001b[39m.\u001b[39;49mS_dfs[\u001b[39m2\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Iwata_Dataset_DB_Stock' object has no attribute 'S_dfs'"
     ]
    }
   ],
   "source": [
    "iwata_stck_ds.S_dfs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "559d4190745a361518ad4d4fb866dbc68a1fa7e52f9c7f667db13a1490771d76"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
